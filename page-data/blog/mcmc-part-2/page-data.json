{"componentChunkName":"component---src-templates-post-js","path":"/blog/mcmc-part-2","result":{"data":{"mdx":{"frontmatter":{"title":"Implementing MCMC - Hamiltonian Monte Carlo","date":"21 January 2021","path":"/blog/mcmc-part-2","author":"Tom","excerpt":"This post is about Hamiltonian Monte Carlo, an MCMC algorithm that builds on the Metropolis algorithm, but uses information about the geometry of the posterior to make better proposals.","tags":["algorithms","bayesian statistics"],"coverImage":null},"id":"226e3618-10de-5bb4-94af-f7c161fd4872","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Implementing MCMC - Hamiltonian Monte Carlo\",\n  \"path\": \"/blog/mcmc-part-2\",\n  \"date\": \"2021-01-21 08:00:00\",\n  \"author\": \"Tom\",\n  \"excerpt\": \"This post is about Hamiltonian Monte Carlo, an MCMC algorithm that builds on the Metropolis algorithm, but uses information about the geometry of the posterior to make better proposals.\",\n  \"tags\": [\"algorithms\", \"bayesian statistics\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"This post is about Hamiltonian Monte Carlo, an MCMC algorithm that builds on the\\nMetropolis algorithm, but uses information about the geometry of the posterior\\nto make better proposals. If you are unfamiliar with the Metropolis algorithm,\\ncheck out the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/blog/mcmc-1\"\n  }, \"previous post in this series\"), \". We'll start by\\nunderstanding how the algorithm works, what problems it solves, then finish up\\nwith a simple implementation.\"), mdx(\"p\", null, \"If you would like to know more about Hamiltonian Monte Carlo I strongly\\nrecommend\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/pdf/1701.02434.pdf\"\n  }, \"A Conceptual Introduction to Hamiltonian Monte Carlo\"), \"\\nby Michael Betancourt, from which I learnt many of the things I'm writing about\\nhere.\"), mdx(\"h2\", null, \"The need for better proposals\"), mdx(\"p\", null, \"In the previous post we successfully applied the Random Walk Metropolis\\nalgorithm to a couple of different problems. Generating a proposal by adding\\nnormally distributed noise to the current location is very simple and easy to\\nimplement, so why would we want to do anything else?\"), mdx(\"p\", null, \"To understand the answer, recall that MCMC algorithms return a sample, of size\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N\"), \" say, from the target distribution. This sample is correlated, which\\nmotivates the introduction of the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"effective sample size\"), \" \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}\"), \". The error\\nin the Monte Carlo estimator decreases like \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}^{-1/2}\"), \", so we can\\ninterpret our correlated sample as having the utility of an independent sample\\nof size \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}\"), \". The goal therefore is to maximise the effective size with the\\navailable resources (time and compute). There are two ways to increase\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}\"), \":\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"We can increase the total number of samples, or\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"We can decrease the correlation in the samples.\")), mdx(\"p\", null, \"These two possibilities are somewhat in tension. Decreasing the correlation in\\nthe samples probably means doing more work per sample which means producing\\nfewer samples in total. On the other, simple fast methods for generating\\nproposals might result in high correlation, but allow for large samples to be\\nproduced because they can be run so quickly.\"), mdx(\"p\", null, \"The Random Walk Metropolis algorithm falls into the latter category here.\\nSampling from a normal distribution to generate the proposal is fast, but it\\nturns out will lead to correlated samples. The following example illustrates why\\nthis is the case. Consider this (unnormalised) probability density, that is\\nconcentrated in an annular region.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" numpy \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"as\"), \" np\\n\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"class\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token class-name\"\n  }, \"DonutPDF\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__init__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" radius\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"3\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" sigma2\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.05\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"radius \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" radius\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sigma2 \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" sigma2\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__call__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        r \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"linalg\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"norm\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"exp\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"r \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"radius\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"**\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sigma2\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, \"Let's reuse the implementation of Random Walk Metropolis from the last post and\\nuse it to draw samples from this density. First recall the proposal distribution\\nwhich simply adds normally distributed noise to the previous sample\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"class\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token class-name\"\n  }, \"NormalProposal\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__init__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"scale \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" scale\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__call__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" sample\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        jump \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"normal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n            scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"sample\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" sample \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" jump\"))), mdx(\"p\", null, \"We combine this with the Metropolis algorithm which generates proposals and\\napplies an accept / reject criterion based on the target density\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"metropolis\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" initial\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" proposal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" iterations\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"10_000\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    samples \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"initial\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" _ \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"range\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"iterations\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        current \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n        proposed \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" proposal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"current\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"<\"), \" target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"proposed\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"current\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"append\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"proposed\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"else\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"append\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"current\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" samples\"))), mdx(\"p\", null, \"We'll run two simulations with different scales in the proposal distribution.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"target \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" DonutPDF\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\nsamples05 \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" metropolis\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"lambda\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"3\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" NormalProposal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.05\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\nsamples1 \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" metropolis\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"lambda\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"3\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" NormalProposal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, \"We can see what's going on by animating the samplers. The underlying contour\\nplot shows the target density\"), mdx(\"undefined\", null, mdx(\"p\", {\n    \"align\": \"center\"\n  }, \"\\n  \"), mdx(\"div\", {\n    \"className\": \"gif-container\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"div\",\n    \"src\": \"/ed47e03702483696f89ce6d4a6ea7b4d/donut_mcmc.gif\"\n  }), \"\\n  \"), mdx(\"p\", null)), mdx(\"p\", null, \"Using both small and large jumps to generate proposals results in highly\\ncorrelated samples. In the former case, each proposal is not very different from\\nthe previous sample so progress through parameter space is slow. In the latter\\ncase, there is a high probability the jump lands us outside the annular region\\nwhere the probability density is vanishingly small, which means there is a high\\nprobability that sample is rejected. When a sample is rejected the previous\\nsample is repeated, which results in high correlation in the samples, and hence\\nsmall \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}\"), \".\"), mdx(\"p\", null, \"Furthermore, we haven't fully explored the target density. Neither sample makes\\nit all of the way around the annulus, and both end up having their samples\\nconcentrated in a small sector.\"), mdx(\"p\", null, \"What we ideally would like is a method for generating proposals that would\\nresult in less correlation in the samples, and better exploration of the target\\ndensity. This is where Hamiltonian Monte Carlo comes in. But before we look at\\nhow it works, I want to quickly argue that this annular density example isn't\\ncompletely contrived.\"), mdx(\"p\", null, \"Consider a standard multivariate normal distribution \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"X \\\\sim \\\\mathcal N(0, I)\"), \".\\nThis is arguably the simplest high-dimensional probability distribution we might\\nlike to sample from. Let's look at how the distribution of distance to the\\norigin in a sample changes as we increase the dimension.\"), mdx(\"p\", {\n    \"align\": \"center\"\n  }, \"\\n  \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"800px\",\n      \"border\": \"8px solid white\",\n      \"borderRadius\": \"8px\",\n      \"background\": \"white\",\n      \"boxSizing\": \"content-box\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/cfe6cfb530e2a4adf235977056077018/bf788/normal_sample_radius.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"32%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABrklEQVQY0zWPTSgEcRjG9+LgJHKRC0eSko+4ODs4KMKqlQhFy4Vod0W74iAlZrO+LnIgynchibSUKHba9bmZdtfsztc2Y2fszM7H3/zHek9P7/O8v97HhBzfF8Uoxk2RJEJSFILjuJtl2ZVYLFZJkmQ3G2fWXrHIgj8YQmiSWOO470GapksZhvHoGYTWb96xsPs9hC/LUrLalNm+1DR//gbgqKoG/kc/6k0IPxdQQ//oCTf2KVlBCYKwaJoGtHQ8gHPA+0FBaTVltLkbKlxngBfllL6QVU0ToROPxzt04D7UzZ4baWwPlaCWUrJX/7wFAhVVgzv56pWUNm4xaPeYioY267MHdsHi5YcBVFTVANIM0yGJogGsmT6X6uauDKCsKF48Gm1NA42bnYew5Dz0/wELrOuN+UMHoGT8BNxjjFEBNokSVK+evUC/OAD9wtEjgEZYaPtCX7glDTTyMycvwLx8+1c5zzJbXDC8O55r3bbVTp3aHz8J209SdPn8z2WKwJnnzwKurL4tW07/ln1k884p8IlOnw8tTfC8kxcEO5BFR9fqtaNq4nASDUbKfwHcIoFJlDZtnQAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"normal sample radius\",\n    \"title\": \"normal sample radius\",\n    \"src\": \"/static/cfe6cfb530e2a4adf235977056077018/78d47/normal_sample_radius.png\",\n    \"srcSet\": [\"/static/cfe6cfb530e2a4adf235977056077018/56d15/normal_sample_radius.png 200w\", \"/static/cfe6cfb530e2a4adf235977056077018/d9f49/normal_sample_radius.png 400w\", \"/static/cfe6cfb530e2a4adf235977056077018/78d47/normal_sample_radius.png 800w\", \"/static/cfe6cfb530e2a4adf235977056077018/64756/normal_sample_radius.png 1200w\", \"/static/cfe6cfb530e2a4adf235977056077018/bf788/normal_sample_radius.png 1584w\"],\n    \"sizes\": \"(max-width: 800px) 100vw, 800px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n\"), mdx(\"p\", null, \"What we see from the histograms is that as the dimension increases, the samples\\nbecome concentrated in an annular region further and further from the origin.\\nWhy does this happen? Well, remember that event probabilities are defined by\\nintegration\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    P(\\\\theta \\\\in A) = \\\\int_A p(\\\\theta)d\\\\theta\"), mdx(\"p\", null, \"So the probability that a sample will land in region \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"A\"), \" depends \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"both\"), \" on the\\ndensity \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta)\"), \" in that region, but also the volume of that region\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"d\\\\theta\"), \". Mass, including probability mass, depends on both density and volume.\"), mdx(\"p\", null, \"The normal density is always largest at the origin in any dimension, but in\\nhigher dimensions there is much more volume away from the origin than there is\\nnear the origin, which means the product of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta)\"), \" and \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"d\\\\theta\"), \" is\\nmaximised in the annular region. High dimensional spaces are weird...\"), mdx(\"p\", null, \"The practical implication of this trade-off between volume and density, is that\\nin high dimensions most of the probability mass is concentrated along narrow\\nsubmanifolds, which are easy to fall off if we generate proposals with a random\\nwalk. To ensure the Markov Chain remains in the high probability mass region we\\nneed to use information about the density in our proposal distribution.\"), mdx(\"h2\", null, \"Hamiltonian Monte Carlo\"), mdx(\"p\", null, \"Hamiltonian Monte Carlo uses ideas from\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Hamiltonian_mechanics\"\n  }, \"Hamiltonian mechanics\"), \" to\\ngenerate a proposal by moving through parameter space according to a carefully\\nconstructed Hamiltonian system.\"), mdx(\"p\", null, \"Here's some not terribly rigorous intuition. Imagine the graph of the negative\\nlog target density over parameter space. The high density regions of the target\\ncorrespond to \\\"wells\\\" and \\\"valleys\\\" on this surface. Now imagine a particle\\nreleased on the surface. It will roll \\\"downhill\\\" into the high density regions.\\nIf instead of simply releasing the particle we were to give it an initial push\\nin a randomly chosen direction, it will roll around the surface, always being\\nattracted towards high density regions, but sometimes having enough momentum\\nthat it rolls out into a lower density region, only to eventually slow down and\\nreturn to the high density regions. If we construct the path that this imaginary\\nparticle would take, we can follow the path for a fixed amount of time, and then\\nuse the place we end up as the proposal in the Metropolis algorithm. That is, in\\nessence, the Hamiltonian Monte Carlo algorithm.\"), mdx(\"p\", null, \"Let's try and make that slightly more rigorous. I'm going to change notation\\nhere to be consistent with the standard notation in Hamiltonian mechanics. We'll\\ndenote by \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q\"), \" the parameters, which take the role of generalised coordinates in\\nthe Hamiltonian system, \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\pi(q)\"), \" the target distribution, and \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \" the conjugate\\nmomenta. Together, \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"(q, p)\"), \" defines \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"phase space\"), \", expanding the \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"d\"), \"-dimensional\\nparameter space into a \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"2d\"), \"-dimensional space.\"), mdx(\"p\", null, \"We will contstruct a Markov chain in phase space. To do so, we need to introduce\\na probability distribution \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\pi(q, p)\"), \" over phase space. Since we ultimately\\nwant to recover a sample from the original target distribution \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\pi(q)\"), \", it's\\nimportant that the marginal distribution of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\pi(q, p)\"), \" over \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q\"), \" is simply\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\pi(q)\"), \". For this reason we define the distribution over phase space by\\nspecifying the conditional distribution of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \" given \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q\")), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\pi(q, p) = \\\\pi(q)\\\\pi(p | q)\"), mdx(\"p\", null, \"which guarantees that \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\pi(q)\"), \" is indeed the marginal distribution. We define\\nthe Hamiltonian as\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    H(q, p) = -\\\\log \\\\pi(q, p) = -\\\\log \\\\pi(q) - \\\\log \\\\pi(p | q)\"), mdx(\"p\", null, \"which decomposes into two terms:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The first, \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"-\\\\log\\\\pi(q)\"), \", is the negative log target density and can be\\nthought of as the \\\"potential energy\\\" in the system. In the hand-wavey\\ngeometric picture from before, it is the height of the particle on the\\nsurface. As the particle rolls down into higher density regions this term\\ndecreases.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The second, \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"-\\\\log \\\\pi(p|q)\"), \", can be thought of as kinetic energy. Unlike the\\nfirst term which is determined by the target, we have full freedom to choose\\nthe form of this term.\")), mdx(\"p\", null, \"A common choice for \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\pi(p | q)\"), \" is a multivariate normal distribution\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\pi(p | q) = \\\\mathcal{N}(p | 0, M)\"), mdx(\"p\", null, \"where \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"M\"), \" is known as the mass-matrix. We have freedom to choose an arbitrary\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"M\"), \", so we would ideally make a choice that makes sampling as easy as possible.\\nAs it turns out, setting \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"M\"), \" to be the inverse of the covariance matrix of the\\n\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"parameters\"), \" is equivalent to transforming parameter space in order to maximally\\ndecorrelate the parameters, which helps sampling. Hence we set\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    M^{-1} := \\\\mathbb{E}_\\\\pi [(q - \\\\mathbb{E}(q))(q - \\\\mathbb{E}(q))^T]\"), mdx(\"p\", null, \"Of course, this quantity is not generally known as \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\pi(q)\"), \" is unknown. In\\npractice, this covariance matrix is estimated from the samples in a warm-up\\nphase, and the mass matrix is then updated for later samples. With \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"M\"), \"\\nestimated, we have\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    -\\\\log \\\\pi(p | q) = \\\\frac 1 2 p^T M^{-1} p + \\\\log |M| + const\"), mdx(\"p\", null, \"Since we are able to work with unnormalised densities, we can drop constants\\nthat are independent of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q\"), \" and \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \".\"), mdx(\"h3\", null, \"Evolving the Hamiltonian system\"), mdx(\"p\", null, \"Hamilton's equations tell us how the system evolves in phase space. We have\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\frac{d q}{d t} = \\\\frac{\\\\partial H}{\\\\partial p} \\\\\\\\\\n    \\\\frac{d p}{d t} = -\\\\frac{\\\\partial H}{\\\\partial q}\"), mdx(\"p\", null, \"Given a sample \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q^{(i)}\"), \" (I'm switching to indexing samples with \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"i\"), \" to avoid a\\nnotation clash with the time evolution of the Hamiltonian system), we set\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q_0 = q^{(i)}\"), \" and sample \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p_0 \\\\sim \\\\mathcal{N}(0, M)\"), \", we then evolve\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"(q_0, p_0)\"), \" for a fixed time \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"T\"), \" to obtain a proposal \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"(q_T, p_T)\"), \", which we\\napply the standard Metropolis acceptance criterion to. If we accept then we have\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q^{(i+1)} = q_T\"), \", otherwise we stay where we are and set \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q^{(i+1)} = q^{(i)}\"), \".\"), mdx(\"p\", null, \"So how do we obtain \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q_T\"), \"? We need to numerically solve the system. Many\\nnumerical solvers suffer from errors that compound over time, meaning that our\\nestimate of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q_T\"), \" gets worse as \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"T\"), \" gets large. Fortunately, we can exploit the\\nstructure of the Hamiltonian system. Hamiltonian dynamics preserve phase space\\nvolume, which can be seen for example by observing that the vector field induced\\nby Hamilton's equations has zero divergence.\"), mdx(\"p\", null, \"A certain class of numerical approximation schemes - known as \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"symplectic\\nintegrators\"), \" - exactly preserve phase space volume, despite being discretised\\napproximations. This limits the extent to which errors can accumulate, because\\nfor example diverging to infinity or spiraling to zero would typically require\\nthat the volume expands or contracts respectively. In particular, unlike naive\\nschemes, errors do not compound, which allows us to approximate longer\\ntrajectories without the error becoming unacceptably large.\"), mdx(\"p\", null, \"A simple and often used symplectic integrator is the so called leapfrog\\nintegrator. This sees us make a half step with \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \", using the half-updated \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \"\\nto update \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q\"), \", then taking another half step with \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \" using the updated \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q\"), \". In\\nother words\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\tilde p = p_n - \\\\frac{\\\\varepsilon}{2} \\\\frac{\\\\partial H}{\\\\partial q}(q_n, p_n) \\\\\\\\\\n    q_{n+1} = q_n + \\\\varepsilon \\\\frac{\\\\partial H}{\\\\partial p}(q_n, \\\\tilde p) \\\\\\\\\\n    p_{n+1} = \\\\tilde p - \\\\frac{\\\\varepsilon}{2} \\\\frac{\\\\partial H}{\\\\partial q}(q_{n+1}, \\\\tilde p)\"), mdx(\"p\", null, \"We can test this with an extremely simple Hamiltonian\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    H(q, p) = \\\\frac{q^2 + p^2}{2}\"), mdx(\"p\", null, \"The figure below compares the leapfrog approximator to Euler's method and a\\nmodified Euler's method (see the appendix at the end of this post for details).\\nThe analytic solution is shown in grey. We see that Euler's method diverges\\ncompletely. The modified Euler doesn't diverge as it is volume preserving, but\\ndoes deviate from the analytic solution at times more than the leapfrog\\nintegrator, while the leapfrog integrator's trajectory is very difficult to\\ndistinguish from the analytic solution.\"), mdx(\"undefined\", null, mdx(\"p\", {\n    \"align\": \"center\"\n  }, \"\\n  \"), mdx(\"div\", {\n    \"className\": \"gif-container\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"div\",\n    \"src\": \"/af1f7edd2c63b0b8a567c4edf2c38980/integrator.gif\"\n  }), \"\\n  \"), mdx(\"p\", null)), mdx(\"p\", null, \"The reason the leapfrog integrator performs better than the modified Euler\\nmethod is because in addition to being volume preserving it is also\\n\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"reversible\"), \", which implies better asymptotics for the global error rate in\\nterms of step size.\"), mdx(\"h2\", null, \"Implementing Hamiltonian Monte Carlo\"), mdx(\"p\", null, \"We have everything we need to implement Hamiltonian Monte Carlo. The algorithm\\nis as follows:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Choose a starting point \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"q^{(0)}\"), \" in parameter space, and fix a step size\\n\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\varepsilon\"), \" and a path length \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"L\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Given parameters \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"q^{(n)}\"), \" we sample \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"p^{(n)} \\\\sim \\\\mathcal N(0, I)\"), \". More\\ngenerally we could sample from \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\mathcal{N}(0, M)\"), \" where\\n\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"M \\\\approx \\\\mathrm{cov}(q)\"), \". We will however keep things simple and just use\\nthe identity matrix.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"We set \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"(q_0, p_0) = (q^{(n)}, p^{(n)})\"), \". Evolve \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"(q_0, p_0)\"), \" for \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"L\"), \" steps\\nusing the leapfrog integrator to obtain \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"(q_L, p_L)\"), \", an approximation of\\n\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"(q(\\\\varepsilon L), p(\\\\varepsilon L))\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Sample \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"r \\\\sim \\\\mathrm{Unif}(0, 1)\"), \" and let \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"q^{(n+1)} = q_L\"), \" if\\n\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\pi(q_L, p_L) / \\\\pi(q^{(n)}, p^{(n)}) < r\"), \", or \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"q^{(n+1)} = q^{(n)}\"), \"\\notherwise.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Repeat\")), mdx(\"p\", null, \"Ok, here goes. First the leapfrog integrator. As before, all implementations are\\noptimised for clarity and simplicity rather than performance.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"leapfrog\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"q0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" p0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" L\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" step_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    q \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" q0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"copy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n    p \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" p0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"copy\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" i \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"range\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"L\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        p \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+=\"), \" target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"grad_log_density\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"q\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" step_size \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \"\\n        q \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+=\"), \" p \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" step_size\\n        p \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+=\"), \" target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"grad_log_density\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"q\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" step_size \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" q\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" p\"))), mdx(\"p\", null, \"We then use that to generate proposals in the Metropolis algorithm. Note we\\nslightly modify the implementation of Metropolis from before since we must\\ncompare ratios of the joint distribution over parameters and momenta rather than\\nthe target distribution.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"hmc\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" initial\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" iterations\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"10_000\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" L\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"50\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" step_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    samples \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"initial\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" _ \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"range\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"iterations\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        q0 \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n        p0 \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"standard_normal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"q0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n        qL\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" pL \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" leapfrog\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"q0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" p0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" L\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" step_size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n        h0 \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \"target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"log_density\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"q0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"p0 \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" p0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"sum\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \"\\n        h \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \"target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"log_density\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"qL\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"pL \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" pL\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"sum\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \"\\n        log_accept_ratio \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" h0 \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \" h\\n\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"<\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"exp\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"log_accept_ratio\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"append\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"qL\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"else\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"append\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"q0\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" samples\"))), mdx(\"p\", null, \"We also slightly redesign the target, as we require evaluations of the gradient\\nof the log density of the target. In this example I've hard-coded the gradient,\\nbut proper implementations typically use some form of autodiff to calculate\\ngradients.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"class\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token class-name\"\n  }, \"DonutPDF\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__init__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" radius\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"3\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" sigma2\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.05\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"radius \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" radius\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sigma2 \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" sigma2\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"log_density\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        r \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"linalg\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"norm\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"r \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"radius\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"**\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sigma2\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"grad_log_density\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        r \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"linalg\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"norm\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" r \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"==\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"zeros_like\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" x \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"radius \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" r \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"sigma2\"))), mdx(\"p\", null, \"We can then draw samples\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"hmc_samples \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" hmc\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"DonutPDF\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"lambda\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"3\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \";\")))), mdx(\"p\", null, \"The below animation shows what's going on. On each iteration we compute the\\ntrajectory according to the Hamiltonian system, then after a fixed time we stop\\nand use the end point as a proposal in the Metropolis algorithm. In the\\nanimation, the trajectory flashes green or red depending on whether the proposal\\nis accepted or rejected respectively.\"), mdx(\"undefined\", null, mdx(\"p\", {\n    \"align\": \"center\"\n  }, \"\\n  \"), mdx(\"div\", {\n    \"className\": \"gif-container\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"div\",\n    \"src\": \"/e87eb0425ff3076b5a7b531c784d7b67/donut_hmc.gif\"\n  }), \"\\n  \"), mdx(\"p\", null)), mdx(\"p\", null, \"We see that not only is the acceptance rate very high, but also the Markov chain\\nquickly finds its way around the donut and covers parameter space quite evenly.\\nThe combination of a high acceptance rate and the potential to take large steps\\nwill result in a low auto-correlation and hence higher effective sample size.\"), mdx(\"p\", null, \"Of course, calculating the trajectories of the Hamiltonian system at each time\\nstep is significantly more computationally expensive than generating a proposal\\nby adding normally distributed noise. However, in practice it often turns out\\nthat the decrease in auto-correlation in the samples far outweighs the reduction\\nin the number of samples, so we still get a better effective sample size which\\nis a much better measure of the quality of our sample than the raw sample size.\"), mdx(\"p\", null, \"Let's finish up by comparing the two Random Walk Metropolis algorithms with\\ndifferent scales from earlier to Hamiltonian Monte Carlo.\"), mdx(\"undefined\", null, mdx(\"p\", {\n    \"align\": \"center\"\n  }, \"\\n  \"), mdx(\"div\", {\n    \"className\": \"gif-container\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"div\",\n    \"src\": \"/636e3075fa2a3542c02d8584229acb72/donut_compare.gif\"\n  }), \"\\n  \"), mdx(\"p\", null)), mdx(\"p\", null, \"Even for this simple example the results are pretty striking. Random Walk\\nMetropolis with small jumps makes small and limited progress around the donut in\\nthe first 1000 samples. With a larger jump size it manages to make it all the\\nway round, but the acceptance rate is low and the samples are not very evenly\\nspread. Finally Hamiltonian Monte Carlo achieves an extremely high acceptance\\nrate and has very good coverage of the distribution. Even without calculating\\nanything it's pretty clear that the sample from Hamiltonian Monte Carlo is the\\nhighest quality of the three.\"), mdx(\"h2\", null, \"Summary\"), mdx(\"p\", null, \"The effective sample size is a good measure of the quality of a sample from a\\nMCMC sampler. We can increase the effective sample size by either drawing more\\nsamples, or decreasing the auto-correlation in the samples. Random-Walk\\nMetropolis which we saw in the first post is able to draw a large number of\\nsamples very quickly, but struggles to make good proposals as the dimension of\\nparameter space increases: either it moves through parameter space very slowly\\nor the proposals have a low acceptance rate. In either case the auto-correlation\\nin the sample is high.\"), mdx(\"p\", null, \"Hamiltonian Monte Carlo defines flows through parameter space along which the\\nsampler travels to generate new proposals. This means the sampler can step\\nfurther away from the previous sample while retaining a high acceptance\\nprobability. Each sample is more computationally expensive as a result, but we\\nfrequently see enough of a reduction in the auto-correlation in the sample for\\nthe trade-off to be worthwhile.\"), mdx(\"p\", null, \"One thing we didn't discuss was how to choose the integration time \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"T\"), \", or\\nequivalently in the approximation the step size \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\varepsilon\"), \" and the number of\\nsteps \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"L\"), \". If we choose \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\varepsilon\"), \" to be too large we might incur\\nunacceptably large error, but too small and the exploration of parameter space\\nwill be very slow. Similarly if \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"L\"), \" is too small we won't move very far through\\nparameter space, but too large and we incur a large computational cost computing\\nthe flow, some of which may be wasted if the sampler covers old ground (imagine\\nin the donut picture we do multiple laps before making a proposal).\"), mdx(\"p\", null, \"There is no general combination of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\varepsilon\"), \" and \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"L\"), \" that will work for all\\nproblems, because what a suitable value is depends on the target. Even worse,\\nHamiltonian Monte Carlo has been found to be quite sensitive to these parameter\\nchoices, and a bad choice can destroy the utility of the sampler. In the next\\npost we will look at the No U-Turn Sampler (NUTS), a modification of Hamiltonian\\nMonte Carlo that is able to choose appropriate \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\varepsilon\"), \" and \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"L\"), \"\\nautomatically, making it much easier to apply in practice.\"), mdx(\"p\", null, \"Full code for all of the plots and animations in this post is available\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://gist.github.com/tcbegley/a209773e77ae90e25ba570aab88afad5\"\n  }, \"here\"), \".\"), mdx(\"h2\", null, \"Appendix\"), mdx(\"p\", null, \"When introducing the leapfrog integrator we compared to two other approximation\\nschemes, the details of which are as follows. First Euler's method. Given a step\\nsize \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\varepsilon\"), \" we produce sequences of approximations\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q_n \\\\approx q(n\\\\varepsilon)\"), \" and \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p_n \\\\approx p(n\\\\varepsilon)\"), \" via the\\nrecurrence relations\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    q_{n+1} = q_n + \\\\varepsilon \\\\frac{\\\\partial H}{\\\\partial p}(q_n, p_n) \\\\\\\\\\n    p_{n+1} = p_n - \\\\varepsilon \\\\frac{\\\\partial H}{\\\\partial q}(q_n, p_n)\"), mdx(\"p\", null, \"As we saw this method can accumulate error leading to divergence. A modification\\nto Euler's method sees us instead update \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \" using the updated value \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q_{n+1}\")), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    q_{n+1} = q_n + \\\\varepsilon \\\\frac{\\\\partial H}{\\\\partial p}(q_n, p_n) \\\\\\\\\\n    p_{n+1} = p_n - \\\\varepsilon \\\\frac{\\\\partial H}{\\\\partial q}(\\\\mathbf{q_{n+1}}, p_n)\"), mdx(\"p\", null, \"This method is volume preserving, which results in much better guarantees on the\\nerror rate. The leapfrog integrator takes this one step further and partially\\nupdates \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \", uses the partial update to update \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q\"), \", then completes the update of\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \" with the updated \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"q\"), \". This modification adds a symmetry which ensures\\nreversibility and further improves the error bounds.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"This post is about Hamiltonian Monte Carlo, an MCMC algorithm that builds on the Metropolis algorithm, but uses information about the geometry of the posterior to make better proposals."}},"pageContext":{"next":null,"previous":{"frontmatter":{"path":"/blog/mcmc-part-1","title":"Implementing MCMC - the Metropolis algorithm","tags":["algorithms","bayesian statistics"]},"fields":{"collection":"posts"},"fileAbsolutePath":"/home/runner/work/tcbegley.github.io/tcbegley.github.io/src/content/posts/mcmc-part-1.md"}}},"staticQueryHashes":["1425477374","3128451518"]}