{"componentChunkName":"component---src-templates-post-js","path":"/blog/mcmc-part-1","result":{"data":{"mdx":{"frontmatter":{"title":"Implementing MCMC - the Metropolis algorithm","date":"19 January 2021","path":"/blog/mcmc-part-1","author":"Tom","excerpt":"I'm a big fan of probabilistic modelling and Bayesian inference. In fact at the time of writing that's the only topic I've written about on this blog so perhaps that's blindingly obvious...","tags":["algorithms","bayesian statistics"],"coverImage":null},"id":"7347451e-e67d-5113-8f64-385efb84844d","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Implementing MCMC - the Metropolis algorithm\",\n  \"path\": \"/blog/mcmc-part-1\",\n  \"date\": \"2021-01-19 08:00:00\",\n  \"author\": \"Tom\",\n  \"excerpt\": \"I'm a big fan of probabilistic modelling and Bayesian inference. In fact at the time of writing that's the only topic I've written about on this blog so perhaps that's blindingly obvious...\",\n  \"tags\": [\"algorithms\", \"bayesian statistics\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"I'm a big fan of probabilistic modelling and Bayesian inference. In fact at the\\ntime of writing that's the only topic I've written about on this blog so perhaps\\nthat's \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"blindingly\"), \" obvious... If you've ever dipped a toe into these warm\\nwaters then you'll likely have come across Markov Chain Monte Carlo (MCMC)\\nalgorithms. They are one of the workhorses of Bayesian inference, being an\\nefficient, general purpose way to draw samples from a probability distribution.\\nIn this series of posts I want to develop some intution for MCMC algorithms by\\nimplementing them and applying them to a toy problem. In this post we'll\\nunderstand the need for MCMC algorithms and learn about the Metropolis\\nalgorithm, the original MCMC algorithm and the foundation for many more advanced\\nalgorithms that were developed later. Let's get started!\"), mdx(\"h2\", null, \"What problem are we solving?\"), mdx(\"p\", null, \"If you've not really worked with MCMC algorithms before, it might not be\\nimmediately obvious why we're so interested in drawing samples from a\\nprobability distribution in the first place. To understand why, let's take a\\nstep back and consider what problem we're actually trying to solve. Imagine we\\nhave a probability distribution over \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta\"), \" - characterised by density\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta)\"), \" - about which we want to answer certain questions.\"), mdx(\"p\", null, \"Note that I'm (semi-)implicitly assuming \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta\"), \" to be modelled by a continuous\\nprobability distribution here, so that we integrate over \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta\"), \" against\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta)d\\\\theta\"), \". This is primarily for notational convenience at this stage,\\nwe could consider an arbitrary probability distribution characterised by\\nprobability measure \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"P(\\\\theta)\"), \" in which case we can integrate directly against\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"dP(\\\\theta)\"), \". In a later post, when we get on to the topic of Hamiltonian Monte\\nCarlo, we will need to make some continuity assumptions.\"), mdx(\"p\", null, \"Essentially every quantity that we might be interested in to answer questions\\nabout this distribution can be characterised in terms of integrals. An obvious\\nexample would be the expected value of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta\")), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\mathbb E [\\\\theta] = \\\\int \\\\theta p(\\\\theta)d\\\\theta\"), mdx(\"p\", null, \"and similarly variances or covariances are simply integrals also. Perhaps\\nslightly less obviously, event probabilities can also be characterised as\\nintegrals, since they are the expected value of the\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Indicator_function\"\n  }, \"indicator function\"), \" of that\\nevent\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    P(\\\\theta \\\\in A) = \\\\mathbb E [\\\\chi_A(\\\\theta)] = \\\\int_A p(\\\\theta)d\\\\theta\"), mdx(\"p\", null, \"If \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta\"), \" is scalar, quantiles such as the median can be characterised via\\nintegrals\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\mathrm{median}(\\\\theta) := \\\\sup\\\\left\\\\{x ~ \\\\bigg| ~ \\\\int_{-\\\\infty}^x p(\\\\theta)d\\\\theta \\\\leq 0.5 \\\\right\\\\}\"), mdx(\"p\", null, \"So the problem of doing inference on a probability distribution reduces to\\nevaluating integrals. What we would like is a general way to evaluate or\\napproximate these integrals.\"), mdx(\"p\", null, \"When we first learn about integration, the focus is usually on evaluating\\nintegrals analytically. In reality it isn't hard to construct examples where\\nthis isn't possible, even in one dimension. If we want to evaluate a high\\ndimensional integral we often will have no choice but to numerically approximate\\nit. So what are our options?\"), mdx(\"h2\", null, \"Approximating integrals\"), mdx(\"p\", null, \"Many algorithms have been developed for approximating integrals, they can\\nbroadly be split into two categories: deterministic and stochastic approaches.\\nWe'll suppose that given some function \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"f(\\\\theta)\"), \" we want to evaluate\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\int f(\\\\theta)p(\\\\theta)d\\\\theta\"), mdx(\"h3\", null, \"Deterministic approaches\"), mdx(\"p\", null, \"Deterministic approaches typically start with some kind of grid of points\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_i\"), \" for \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"i = 1, \\\\dots, N\"), \", then approximate the integral with a weighted\\nsum of evaluations of the integrand on the grid\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\int f(\\\\theta)p(\\\\theta)d\\\\theta \\\\approx \\\\sum_{i=1}^N w_i f(\\\\theta_i) p(\\\\theta_i)\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Simpson's_rule\"\n  }, \"Simpson's rule\"), \" for example is a\\nparticular special case of this, but there are many variants. There are two big\\ndrawbacks to these deterministic approaches that mean we will ultimately be\\nuninterested in using them for inference:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"If we were to use a na\\xEFve strategy for chosing grid points, then the number\\nof points required to reach some acceptable level of error increases\\nexponentially with the dimension of the space we are integrating over. For\\nexample, if we were using a uniform grid, then in one dimension we might\\nrequire \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N\"), \" points for an acceptable level of error. In two dimensions, to\\nachieve the same \\\"resolution\\\" we would need a grid of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N^2\"), \" points, and so on\\nso that in \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"d\"), \" dimensions we construct a grid of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N^d\"), \" points. Deterministic\\nevaluation of integrals quickly becomes intractable as a result. There are of\\ncourse algorithms that try to solve such problems, using adaptive grids and\\nother tricks, but they will mostly be more complicated and less general.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"A second problem, which is particularly relevant in Bayesian inference, is\\nthat we need to evaluate the density \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta)\"), \", whereas typically we might\\nonly know the density up to a multiplicative constant. We will see shortly\\nthat MCMC methods don't have this problem, as they can proceed with an\\nunnormalised form of the density.\"))), mdx(\"h3\", null, \"The Monte Carlo approximation\"), mdx(\"p\", null, \"The Monte Carlo approximation is a stochastic integral approximation. Given\\nsamples \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_s\"), \" for \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"s = 1, \\\\dots, N\"), \" we approximate\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\int f(\\\\theta)p(\\\\theta)d\\\\theta \\\\approx \\\\frac 1 N \\\\sum_{s=1}^N f(\\\\theta_s)\"), mdx(\"p\", null, \"that is we average evaluations of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"f\"), \" on the samples \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_s\"), \". Note that\\nunlike the deterministic approaches above, the approximation does not feature\\nevaluations of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \". This is instead accounted for by the fact that samples\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_s\"), \" will be concentrated where \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \" is large. As a result we can think of\\nthe samples as being like an adaptive grid, which places more grid points in\\nregions that have more influence on the value of the integral.\"), mdx(\"p\", null, \"From the\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Central_limit_theorem\"\n  }, \"Central Limit Theorem\"), \" we\\ncan deduce that asymptotically as \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N\\\\rightarrow \\\\infty\")), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\frac 1 N \\\\sum_{s=1}^N f(\\\\theta_s) \\\\sim \\\\mathcal N \\\\left(\\\\mathbb{E}_p(f(\\\\theta)), \\\\frac{\\\\mathrm{var}_p(f(\\\\theta))}{N}\\\\right)\"), mdx(\"p\", null, \"from which we learn that the variance of the Monte Carlo estimator, or\\nspecifically the asymptotics thereof, are \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"independent of the dimension of\\n\", mdx(\"span\", {\n    parentName: \"em\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta\")), \"! This remarkable fact is one of the key reasons that the Monte Carlo\\nestimator is so powerful when it comes to estimating high dimensional integrals.\"), mdx(\"h2\", null, \"Drawing samples\"), mdx(\"p\", null, \"It might seem like we just got a free lunch, which should make you suspicious.\\nHow did we manage to get rid of the exponential scaling just by introducing some\\nstochasticity? In truth we didn't get rid of it, we've just traded one problem\\nfor another. Rather than approximating integrals we need to figure out how to\\ndraw independent samples from an arbitrary probability distribution. A na\\xEFve\\napproach will have the same exponential scaling with dimension as the\\ndeterministic integral evaluation, so really we've just shifted the complexity\\ninto the drawing of samples.\"), mdx(\"p\", null, \"An interesting observation however, which opens the door to MCMC algorithms is\\nthat the independence requirement can be relaxed. We can use correlated samples\\ninstead, but the variance in the estimator will decay slower than \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N^{-1/2}\"), \". In\\nfact we can quantify the price we pay for not having independent samples. We\\nintroduce \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}\"), \", the effective sample size, defined as\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    N_{eff} := \\\\frac{N}{1 + 2 \\\\sum_{k=1}^\\\\infty \\\\rho_k}\"), mdx(\"p\", null, \"where \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\rho_k\"), \" are the lag-\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"k\"), \" auto-correlations in the sample. It can be shown\\nthat the variance in the estimator decays like \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}^{-1/2}\"), \", and so in some\\nsense our \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N\"), \" correlated samples are \\\"as good as\\\" \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}\"), \" independent samples.\"), mdx(\"p\", null, \"Notice that the less correlated the samples, the larger \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}\"), \", so when\\ndrawing samples we want to find a balance of drawing as many samples as possible\\n(increasing \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N\"), \") with making sure that those samples are as uncorrelated as\\npossible (reducing the denominator). Both of these things will increase\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"N_{eff}\"), \", but they are likely to be in tension.\"), mdx(\"h3\", null, \"Markov chains\"), mdx(\"p\", null, \"A Markov chain is a sequence of random variables, where each variable depends\\nonly on the previous variable. That is \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_1, \\\\dots, \\\\theta_k\"), \" satisfies\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta_k ~ | ~ \\\\theta_1, \\\\dots, \\\\theta_{k-1}) = p(\\\\theta_k ~ | ~ \\\\theta_{k-1})\"), \".\\nAs a result, Markov chains can be characterised by transition kernel\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"T(\\\\theta_k | \\\\theta_{k-1})\"), \", which represents the probability of transitioning\\nfrom \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_{k-1}\"), \" to \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_k\"), \" in one step.\"), mdx(\"p\", null, \"A classic example is that of a random walk, where\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_k = \\\\theta_{k-1} + \\\\varepsilon_k\"), \". That is, at each time step we take a\\nstep in the direction \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\varepsilon_k\"), \" which is drawn from some appropriate\\nprobability distribution like a multivariate normal distribution.\"), mdx(\"p\", null, \"Markov chains have some nice convergence properties assuming certain conditions\\nare satisfied. There's a lot of theory behind these results that I won't go into\\nin detail in this post. The key thing to know is that under certain regularity\\nconditions, the chain will have a so-called \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"stationary distribution\"), \". The\\nstationary distribution is unique, and invariant under the transition kernel.\\nThat means if we sample a starting point from the stationary distribution, then\\ntake a step according to the transition kernel, the result is also distributed\\naccording to the stationary distribution. Furthermore we have that the Markov\\nchain will converge to that stationary distribution from any starting position.\"), mdx(\"p\", null, \"The practical implication therefore is that if we can construct a Markov chain\\nwhose stationary distribution is the target distribution, then we know that\\nsamples from the chain will look more and more like samples from the target\\ndistribution if we evolve the chain for long enough. This is precisely what the\\nMetropolis algorithm does.\"), mdx(\"h3\", null, \"The Metropolis algorithm\"), mdx(\"p\", null, \"We want to construct a Markov chain whose stationary distribution is the target\\ndistribution. To do so we need two ingredients:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The target probability distribution \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta)\"), \" (which need not be\\nnormalised)\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"A jumping / proposal distribution \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"J(\\\\theta_{t+1} ~ | ~ \\\\theta_t)\"), \", which\\ngiven the current location in parameter space \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_t\"), \", defines a\\nprobability distribution over possible locations at the next time step. The\\nMetropolis algorithm requires that this proposal distribution is symmetric so\\nthat \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"J(\\\\theta ~ | ~ \\\\hat \\\\theta) = J(\\\\hat \\\\theta ~ | ~ \\\\theta)\"), \", i.e. the\\nprobability of jumping from A to B is the same as the probability of jumping\\nfrom B back to A. This requirement can be relaxed.\")), mdx(\"p\", null, \"The idea of the algorithm is to evolve the Markov chain by sampling a proposal\\nfrom the proposal distribution, then applying an accept / reject criterion based\\non the target distribution that will ensure the chain as a whole has the correct\\nstationary distribution. It is worth understanding this setup well, as many more\\nadvanced algorithms follow the same structure, they just use clever choices of\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"J\"), \".\"), mdx(\"p\", null, \"The details are as follows:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Choose a starting point \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_0\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Given \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_t\"), \", sample \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta^*\"), \" from the proposal distribution\\n\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"J(\\\\theta^* ~ | ~ \\\\theta_t)\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Sample \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"r \\\\sim \\\\mathrm{Unif}(0, 1)\"), \". If \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"r < p(\\\\theta^*) / p(\\\\theta_t)\"), \", set\\n\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_{t+1} = \\\\theta^*\"), \", otherwise set \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_{t+1} = \\\\theta_t\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Repeat \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"inlineMath\"\n  }, \"N\"), \" times.\")), mdx(\"p\", null, \"The ratio \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta^*) / p(\\\\theta_t)\"), \" represents how much more likely the\\nproposal \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta^*\"), \" is under the target distribution than the current sample\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_t\"), \". If the proposal is in a region of higher density than the current\\nsample it will always be accepted (because \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"r \\\\leq 1\"), \"), otherwise if the\\nproposal would take the chain to a region of lower probability (under the target\\ndistribution), there is a non-zero chance the proposal is rejected and the chain\\nstays where it is. A proof that this procedure results in the target\\ndistribution being the stationary distribution is included in the appendix at\\nthe end of this post.\"), mdx(\"p\", null, \"Notice that because the target distribution only enters the algorithm in the\\nform of this ratio, it is ok if we only know the target distribution up to a\\nmultiplicative constant independent of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta\"), \", as such constants will cancel\\nout anyway. This is exactly the situation we find ourselves in when doing\\nBayesian inference. It's easy to specify the unnormalised prior as the product\\nof the prior and the likelihood\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    p(\\\\theta | y) = \\\\frac{p(\\\\theta)p(y | \\\\theta)}{p(y)} \\\\propto p(\\\\theta)p(y | \\\\theta)\"), mdx(\"p\", null, \"Ordinarily the data marginal / evidence in the denominator is hard to calculate\\n(it is itself defined in terms of an integral over \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta\"), \"), but thanks to the\\nMetropolis algorithm we needn't calculate it and can instead just work with the\\nunnormalised product.\"), mdx(\"h2\", null, \"Implementing Metropolis\"), mdx(\"p\", null, \"Let's have a go at implementing the Metropolis algorithm. To do so we'll need to\\nspecify a proposal distribution \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"J\"), \" which we haven't discussed yet. One of the\\nsimplest, and perhaps most common, choices is a normal distribution\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\theta^* | \\\\theta_t \\\\sim \\\\mathcal{N}(\\\\theta_t, \\\\sigma^2)\"), mdx(\"p\", null, \"where \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\sigma\"), \" is a tunable parameter. That is to say, at each step the proposal\\nis simply the current sample with some normally distributed noise applied. This\\nis very easy to implement, and is known as Random Walk Metropolis, as the\\nproposal distribution is defining a random walk in parameter space.\"), mdx(\"p\", null, \"Below is a simple implementation of the metropolis algorithm. It expects an\\nunnormalised density \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"target\"), \" corresponding to the target distribution, a\\nfunction \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"initial\"), \" that can produce an initial sample, and a proposal\\ndistribution \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"proposal\"), \" that returns a sampled proposal given the current point.\\nThe implementation could certainly be improved, I'm attempting to optimise for\\nclarity rather than anything else.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"import\"), \" numpy \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"as\"), \" np\\n\\n\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"metropolis\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" initial\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" proposal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" iterations\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"100_000\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    samples \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), \"initial\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" _ \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"range\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"iterations\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        current \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), \"\\n        proposed \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" proposal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"current\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"<\"), \" target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"proposed\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"current\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"append\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"proposed\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"else\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            samples\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"append\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"current\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" samples\"))), mdx(\"p\", null, \"You'll notice that the core logic of this algorithm is really very simple.\\nAbstracting away the proposal it's only a handful of lines of code. Don't be\\nfooled by the simplicity though, this basic structure can be extremely powerful.\"), mdx(\"p\", null, \"Let's implement a proposal distribution. This can quite neatly be encapsulated\\nwith a custom class which we make callable by implementing the \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"__call__\"), \" magic\\nmethod.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"class\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token class-name\"\n  }, \"NormalProposal\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__init__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"scale \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" scale\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__call__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" sample\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        jump \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"normal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n            scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"sample\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" sample \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" jump\"))), mdx(\"p\", null, \"Instantiating \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"NormalProposal\"), \" produces a callable object that adds normally\\ndistributed noise with the specified scale to the argument.\"), mdx(\"p\", null, \"We also need a target distribution to sample from. Let's start simple and use a\\nmultivariate normal distribution. Again, this can be quite neatly implemented as\\na callable object.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"class\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token class-name\"\n  }, \"MultivariateNormalPDF\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__init__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" mean\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" variance\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"mean \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" mean\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"variance \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" variance\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"inv_variance \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"linalg\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"inv\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"variance\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__call__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" sample\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"exp\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.5\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"sample \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"mean\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"T\\n            @ self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"inv_variance\\n            @ \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"sample \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"mean\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, \"Notice that this object returns an unnormalised form of the density, ordinarily\\nthere would be an additional factor depending on the determinant of the\\ncovariance matrix.\"), mdx(\"p\", null, \"We can put this all together and draw samples\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"samples \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" metropolis\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    initial\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"lambda\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    proposal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"NormalProposal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n    iterations\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"50_000\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, \"I ran this four times with different starting points each time. The results are\\nshown below\"), mdx(\"undefined\", null, mdx(\"p\", {\n    \"align\": \"center\"\n  }, \"\\n  \"), mdx(\"div\", {\n    \"className\": \"gif-container\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"div\",\n    \"src\": \"/e08eecdd043aba51fb8b589f2f3eac0d/rw-metropolis.gif\"\n  }), \"\\n  \"), mdx(\"p\", null)), mdx(\"p\", null, \"You can see from the animation that the early samples, when the chain is still\\nfinding its way to the high density region of the target distribution are not\\nvery representative of the target, however once the chains have found their way\\nto the high density region they explore it fully and mix well.\"), mdx(\"p\", null, \"Understanding when the chain has converged is one of the challenges of MCMC.\\nVarious diagnostic metrics have been introduced which I won't go into here. One\\nbasic idea that suggests itself when you look at the animation above is to run\\nmultiple chains and compare them after some samples have elapsed. In the simple\\nexample, the chains quickly become indistinguishable, suggesting (but not\\nproving) that they have converged to the shared target. The \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\hat R\"), \" metric\\nprovides a more rigourous quantification of this observation than the \\\"eyeball\\nmetric\\\" that we used.\"), mdx(\"h2\", null, \"Fitting Logistic regression with the Metropolis algorithm\"), mdx(\"p\", null, \"Sampling from a normal distribution is a little underwhelming. Let's finish up\\nthis post by trying something a bit more interesting. Let's generate some simple\\ndata for classification.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"sigmoid\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"arr\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"exp\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \"arr\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\\nalpha \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1.5\"), \"\\nbeta \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1.5\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1.6\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\ndata \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"multivariate_normal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n    np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"zeros\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"4\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"4\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"10\"), \"\\n\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\nlabels \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"binomial\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" p\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"sigmoid\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"data @ beta \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" alpha\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, \"This gives us ten data points with five belonging to each class\"), mdx(\"p\", {\n    \"align\": \"center\"\n  }, \"\\n  \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"792px\",\n      \"border\": \"8px solid white\",\n      \"borderRadius\": \"8px\",\n      \"background\": \"white\",\n      \"boxSizing\": \"content-box\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/5990069e53b98ebeb9cb9f37eca31753/59f54/data.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"90.99999999999999%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB00lEQVQ4y6VUyU4CQRAt9eLBGPhAvsOECxfvhIMaIokHvgD4AxM3OLCGbVwOJh4MUQacfej21WwOMpJRO7yp6uqq16+L6aFyuUyVSoXG4zF1u13q9/up0ev1PNtut6lWq1Gj0SAqFotUKpVIUZT9TqeTRUIGianB+SA8BOFOvV4nklLuAjSbzY4dx3m1bVuBfUwD5N7DPuu6fjkYDA6Hw6FHuMeEi8XiXP5xgPQFLctMp9MvQlVVT3lRCGEDKyEksAqAuZRBTMThcA2UPo5Go8xkMllTeBpuiEThefpCSlPzoyuXd/P9wDJpQPi0nRC5UTEX8mP5JoVr+77wl7cSLpfLdYX841pW5joyohciJnQL4Xw+PwuSIkJvWIYUfHQudESk+fcKuSxQxipt9V2+oZ2GJcIm/FIh+9ocpK5HoH64nipVw1+9SkH4Uw+9ADg1S8aUpegh3sNNhcI/HivyjwqFOnw73Wtz4gsTFuDGwd1kfI/zJQgIH5IUXvzj6r2CMBsShh+HI03TxtjtCpe9ZZrmHcMwjKZlWbeINbF2w3O2yG3BXiOnjf7X8LU6ACgaTIqxF9gdtnE/we6Gc37kcjkqFAobhGs2KZZkeeTzeapWq/QJDNaZC2RLZtcAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"data\",\n    \"title\": \"data\",\n    \"src\": \"/static/5990069e53b98ebeb9cb9f37eca31753/59f54/data.png\",\n    \"srcSet\": [\"/static/5990069e53b98ebeb9cb9f37eca31753/56d15/data.png 200w\", \"/static/5990069e53b98ebeb9cb9f37eca31753/d9f49/data.png 400w\", \"/static/5990069e53b98ebeb9cb9f37eca31753/59f54/data.png 792w\"],\n    \"sizes\": \"(max-width: 792px) 100vw, 792px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n\"), mdx(\"p\", null, \"Let's see if we can separate them with a logistic regression model. A standard\\nsetup would be something like the following\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\alpha \\\\sim \\\\mathcal{N}(0, 5^2) \\\\\\\\\\n    \\\\beta_i \\\\sim \\\\mathcal{N}(0, 5^2) \\\\\\\\\\n    y_i \\\\sim \\\\mathrm{Bernoulli}\\\\left(\\\\frac{1}{1 + \\\\exp(-(\\\\alpha + \\\\beta^T x_i))}\\\\right)\"), mdx(\"p\", null, \"We want to sample from \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\alpha, \\\\beta | \\\\mathbf y, \\\\mathbf x)\"), \". Let\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    \\\\eta_i = \\\\frac{1}{1 + \\\\exp(-(\\\\alpha + \\\\beta^T x_i))}\"), mdx(\"p\", null, \"By Bayes rule we have\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    p(\\\\alpha, \\\\beta | \\\\mathbf y, \\\\mathbf x) \\\\propto \\\\exp\\\\left( \\\\frac{-\\\\alpha^2 - \\\\|\\\\beta\\\\|^2}{50} \\\\right) \\\\prod_i \\\\eta_i^{y_i} (1 - \\\\eta_i)^{1 - y_i}\"), mdx(\"p\", null, \"That looks easy enough to implement, so let's try it!\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"class\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token class-name\"\n  }, \"LogisticPDF\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__init__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" y\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" prior_scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"5\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"x \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" x\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"y \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" y\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"prior_scale \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" prior_scale\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token decorator annotation punctuation\"\n  }, \"@staticmethod\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"_likelihood\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" y\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" alpha\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" beta\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        eta \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"exp\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"alpha \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"dot\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"beta\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"if\"), \" y \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"==\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" eta\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), \" eta\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__call__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" sample\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        alpha\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" beta \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" sample\\n        prior \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"exp\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n            \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"-\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"alpha \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"**\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"linalg\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"norm\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"beta\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"**\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"/\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"prior_scale \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"**\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"2\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n        likelihood \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"1\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"for\"), \" x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" y \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"in\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token builtin\"\n  }, \"zip\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"y\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n            likelihood \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*=\"), \" self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"_likelihood\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"x\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" y\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" alpha\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" beta\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" prior \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"*\"), \" likelihood\"))), mdx(\"p\", null, \"The way I've written this, each sample is a tuple consisting of an \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\alpha\"), \"\\nsample and a \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\beta\"), \" sample, so we also need to slightly rewrite the normal\\nproposal from before.\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"class\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token class-name\"\n  }, \"NormalProposalLogistic\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__init__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"scale \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" scale\\n\\n    \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"def\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token function\"\n  }, \"__call__\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" sample\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \"\\n        alpha\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" beta \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" sample\\n        alpha_jump \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"normal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n            scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"alpha\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        beta_jump \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"random\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"normal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"\\n            scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"self\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"scale\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" size\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \"beta\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"shape\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\n        \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"return\"), \" alpha \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" alpha_jump\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" beta \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"+\"), \" beta_jump\"))), mdx(\"p\", null, \"That's it, we can use the same \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"metropolis\"), \" function from before to draw samples\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-python\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"target \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" LogisticPDF\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"data\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" labels\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\nproposal \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" NormalProposalLogistic\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0.1\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), \"\\nsamples \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token operator\"\n  }, \"=\"), \" metropolis\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"target\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token keyword\"\n  }, \"lambda\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \":\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), \"np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" np\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \".\"), \"array\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"[\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" \", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token number\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \"]\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \",\"), \" proposal\", mdx(\"span\", {\n    parentName: \"code\",\n    \"className\": \"token punctuation\"\n  }, \")\")))), mdx(\"p\", null, \"This gives us many samples of the coefficients in the model. The posterior\\npredictive distribution is given by averaging the sampling distribution against\\nthe posterior.\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    p(\\\\tilde y | \\\\tilde x, x, y) = \\\\int p(\\\\tilde y | \\\\tilde x, \\\\alpha, \\\\beta)p(\\\\alpha, \\\\beta | x, y) d(\\\\alpha, \\\\beta)\"), mdx(\"p\", null, \"In practice this means making a prediction with each sampled set of coefficients\\nand then averaging the predictions. The result of doing this in our case\\n(discarding the first 10,000 samples to minimise bias from the initialisation)\\nis shown below.\"), mdx(\"p\", {\n    \"align\": \"center\"\n  }, \"\\n  \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"792px\",\n      \"border\": \"8px solid white\",\n      \"borderRadius\": \"8px\",\n      \"background\": \"white\",\n      \"boxSizing\": \"content-box\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/19304a84b100dff5eb4af89ab1fafe78/59f54/logistic-heatmap.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"90.99999999999999%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEZUlEQVQ4y22UC0xTZxTHD32i1FEYk8iAlhaIoPQhGToQJ2Zs02zuEZySCfSWl2hbKAxBIAQCxiwaN+cGE0aAKXOJkIkYDctcGwiB8hJTHotAR+IGHQwBdRnS25595YLWZV/yyzlfbvK7/++eey/sAW9wchj8IAG2wKH/IYXlB2e9JdD6biyYKtLA3NYIVssYAEsC4BkB4LEN4CVSnet18IJowhHwcydCLyIQkio85IKK5Sc8vzlY2PbRPmHPmePCwdZGL8uvZgHwQ/ngo+SBlwLgZSUjPAlSVj5IIQX8K9MhcJYwTrC4UsgRW26G7bBMFVOWv+80jD+e/m32ydPlq6DIpIRv5H3osacANu0tZK0K9SBh50AQqCGgNhNE+F8yCOVcCXbF7saFmmKkJ0w4u/AYh62LXd4JX+VKUxuTA6nLIKYa2c+EBKAgoIoRBK4Q7MdAZCd7ezrh7AapfeToe/blju/t/yw9XDFM/IUVP438IjvVottZ0kzFfTMC+2rGmIQ6CGJrmYRVa6lsaRDgyPcMxewNUucNsHbzVrSe0SFtHce+B4u0pnkII8vbDep6Y3ZKnUGluT4Kupvjz4UEl4QiWyYEOpx9GpHlukvx9mtRaOtsxiHrI0xtGqTD81rR8/2LhtoOc3aVcSTJhAg/Ti0zQi2ISULxCwkJRBiIx3lS1MIWNKsTcdI6gwk1veivqqd9DpxGkGcZ+yzT2qbbHRqiYSORrq5PQcrOY55h9fOEIgeZLuZsCsWL3hIcvdGKB77oREF8BQpi9PTGXScQJInGP+cfanvvDacTjRsRuq0dmUmYShKSQSDBluUmcmg4QVgCvjiQq8OjFwzIispDvlKNXKWado9MRRAlGJetk9rRvq4MZ7pnwhJWMLucFQIZbgHVWpYY9RyxrYgjcTT4h+GDYg3Wt99Dzu5CFO7SII8IOXIVzd+hRhAfNq7cvaXtv1ZzYi0hc+QyXjC7lCeFXK64qpQvwQseIbYbIXLHTIUOZ6an8J3PSDp5GklHIVdBMULSQ/AnhoWmiuw/GiuTsLMOsL2KGcp1r+3sFkE4nBNIq6/6hmP33ljb3Jf5Drv1Ptb1T6MoqQY5MhV6xujRPTKDCFMY4dYUw+TJxOwBfaJqriwNZsvSGOFwTCzbrNgJbeHKr+9+EI/zl4qe2i399P25RzR1eYD23F9Jc2TJNFehJlA0SbjCV6gQItR3ut+M1t2Ki6GmDr4FloNvM0KsLmTjOS2Ys4/ULzaUo32iB+eXnuB3g79jzOmfURBXjFy5avW46/CcQmV6zxWf4Px63zDVD75hcMU3jPn0cKiFhQNNMPVtaeFSV8vY0txMd8+kta+gdag3POeaaWO0vpcjSzJx5ckmktRJD0+WPAxK6lIB+9WPc3ni/SVcMZziBTEJ1xdaPweXF9RtDXCp4L82yWOk+pK/Ib4iB4zKB9yuAoyg4EVhu5ap6+N36beRep7gZ2f2MtIrnNej4gGzzgImFRGKV6/9CzS/MAr6FJfKAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"logistic heatmap\",\n    \"title\": \"logistic heatmap\",\n    \"src\": \"/static/19304a84b100dff5eb4af89ab1fafe78/59f54/logistic-heatmap.png\",\n    \"srcSet\": [\"/static/19304a84b100dff5eb4af89ab1fafe78/56d15/logistic-heatmap.png 200w\", \"/static/19304a84b100dff5eb4af89ab1fafe78/d9f49/logistic-heatmap.png 400w\", \"/static/19304a84b100dff5eb4af89ab1fafe78/59f54/logistic-heatmap.png 792w\"],\n    \"sizes\": \"(max-width: 792px) 100vw, 792px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n\"), mdx(\"p\", null, \"There we have it, a simple logistic regression solved by MCMC. From the heatmap\\nyou can see there is some uncertainty in the decision boundary, a consequence of\\nthe range of plausible parameters that could have given rise to the observed\\ndata. This is just one example of the benefits of inferring a distribution over\\nparameters rather that simply a point estimate.\"), mdx(\"p\", null, \"You'll notice that it was pretty easy to separate concerns in our implementation\\nof Metropolis. Once the core logic was in place (the \", mdx(\"code\", {\n    parentName: \"p\",\n    \"className\": \"language-text\"\n  }, \"metropolis\"), \" function) we\\nwere able to draw samples from a couple of different distributions just by\\nimplementing a target density and a proposal distribution. The fact that we\\ndon't have to normalise the target distribution helped make this very easy for\\nus. In the first example it would have been easy enough to implement a correctly\\nnormalised multivariate normal density, but in the case of the logistic\\nregression it would have been at the very least annoying to do analytically. For\\nmore complex models it's often impossible.\"), mdx(\"h2\", null, \"Conclusion\"), mdx(\"p\", null, \"In this post we learned that statistical inference boils down to evaluating\\n(often analytically intractable) integrals. We saw that the Monte Carlo\\nestimator is a powerful stochastic integral approximator, which means to\\napproximate integrals we can draw samples instead. Though drawing independent\\nsamples can be challenging, we learnt that correlated samples will do just fine,\\nas long as we account for the amount of correlation in the sample when making\\ninferences. The Metropolis algorithm is a general algorithm for sampling from\\nany target distribution by constructing a Markov chain whose stationary\\ndistribution is the target distribution. We implemented the Metropolis algorithm\\nand used it to sample from a multi-variate normal distribution, and to solve a\\nsimple logistic regression problem.\"), mdx(\"p\", null, \"In the next post in this series, we're going to take a look at Hamiltonian Monte\\nCarlo, which uses the geometry of the target distribution to construct a very\\nefficient proposal distribution. We'll learn how it works and then try\\nimplementing it like we did here.\"), mdx(\"p\", null, \"Full code for all of the plots and animations in this post is available\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://gist.github.com/tcbegley/e7b1f22a5d3fffed35d3f1dbffc8daf3\"\n  }, \"here\"), \".\"), mdx(\"h2\", null, \"Appendix - stationarity of the target distribution\"), mdx(\"p\", null, \"We show that the target distribution satisfies\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Detailed_balance#Reversible_Markov_chains\"\n  }, \"detailed balance\"), \"\\nwith respect to the transition kernel induced by the Metropolis algorithm.\\nSpecifically, we want to show for any \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_a\"), \" and \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_b\"), \" we have\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    p(\\\\theta_a)T(\\\\theta_b | \\\\theta_a) = p(\\\\theta_b)T(\\\\theta_a | \\\\theta_b)\"), mdx(\"p\", null, \"where \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"T\"), \" is the transition kernel. Note that the transition kernel incorporates\\nthe accept / reject step and is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"not\"), \" the same as the proposal distribution.\"), mdx(\"p\", null, \"To prove this let's pick arbitrary \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_a\"), \" and \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_b\"), \". Suppose\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta_a) > p(\\\\theta_b)\"), \", which we may do without loss of generality. Then\\nthe proposal \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_a\"), \" will always be accepted from state \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_b\"), \" so\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"T(\\\\theta_a | \\\\theta_b) = J(\\\\theta_a | \\\\theta_b)\"), \" and hence\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    p(\\\\theta_b)T(\\\\theta_a | \\\\theta_b) = p(\\\\theta_b)J(\\\\theta_a | \\\\theta_b)\"), mdx(\"p\", null, \"Going in the other direction, the proposal \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_b\"), \" is accepted from state\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"\\\\theta_a\"), \" with probability \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p(\\\\theta_b) / p(\\\\theta_a)\"), \", so using the fact that\\nthe proposal distribution is assumed to be symmetric\"), mdx(\"div\", {\n    \"className\": \"math\"\n  }, \"    p(\\\\theta_a)T(\\\\theta_b | \\\\theta_a) = p(\\\\theta_a) J(\\\\theta_b | \\\\theta_a) \\\\frac{p(\\\\theta_b)}{p(\\\\theta_a)} = p(\\\\theta_b)J(\\\\theta_a | \\\\theta_b)\"), mdx(\"p\", null, \"from which detailed balance follows, and hence the fact that \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"inlineMath\"\n  }, \"p\"), \" is the\\nstationary distribution of the Markov chain.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"I'm a big fan of probabilistic modelling and Bayesian inference. In fact at the time of writing that's the only topic I've written about on this blog so perhaps that's blindingly obvious..."}},"pageContext":{"next":{"frontmatter":{"path":"/blog/mcmc-part-2","title":"Implementing MCMC - Hamiltonian Monte Carlo","tags":["algorithms","bayesian statistics"]},"fields":{"collection":"posts"},"fileAbsolutePath":"/home/runner/work/tcbegley.github.io/tcbegley.github.io/src/content/posts/mcmc-part-2.md"},"previous":{"frontmatter":{"path":"/blog/bayesian-billiards","title":"Bayesian billiards","tags":["bayesian statistics","interactive"]},"fields":{"collection":"posts"},"fileAbsolutePath":"/home/runner/work/tcbegley.github.io/tcbegley.github.io/src/content/posts/bayesian-billiards.mdx"}}},"staticQueryHashes":["1425477374","3128451518"]}